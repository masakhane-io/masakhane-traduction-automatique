# Masakhane - Une collection dynamique de projets TAL par les Africains, pour les Africains


![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)
[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://join.slack.com/t/masakhane-nlp/shared_invite/enQtODM3ODA3ODE0ODIwLTAyYzg3M2E3Nzg4Y2I3NzgxNDg4MmNlZDE4OTBjMzBjMjg4NTcxMWZlYTg3ZDljMTU4M2FjOTk3MDVjOWM2NGM)

<div align="center">
<img src="https://pbs.twimg.com/profile_images/1255858628986384384/d7Lk9I-w_400x400.jpg" >
</div>

**MASAKHANE** est un effort de recherche pour le Traitement Automatique des Langues (TAL) Africaines qui est OPEN SOURCE, CONTINENTALE, DISTRIBUÉE et DISPONIBLE EN LIGNE. Ce dépôt GitHub héberge de ce fait les données, le code, les résultats ainsi que la recherche pour la construction de résultats de référence ouverts pour le traitement automatique des langues africaines.

Site Web: [masakhane.io](https://www.masakhane.io)

## Objectifs

- **Pour l'Afrique** : Construire et soutenir une communauté de chercheurs en TAL, la connecter et la faire grandir; encourager et partager la recherche, construire des outils utiles pour des applications dans le secteur public (gouvernement), la médecine, la science et l'éducation; permettre la préservation de la langue et augmenter sa visibilité ainsi que sa pertinence au niveau mondial.

- **Pour la recherche en TAL** : Construire des jeux de données ainsi que des outils afin de faciliter la recherche en TAL sur les langues Africaines et poser de nouveaux problèmes de recherche pour enrichir le paysage de la recherche en TAL.

- **Pour la communauté mondiale des chercheurs** : Découvrir les meilleures pratiques pour la recherche distribuée, qui pourront être appliquées par d'autres communautés de recherche émergentes.

## Tableau d'honneur de nos contributeurs
[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/0)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/0)[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/1)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/1)[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/2)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/2)[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/3)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/3)[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/4)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/4)[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/5)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/5)[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/6)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/6)[![](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/images/7)](https://sourcerer.io/fame/jaderabbit/masakhane-io/masakhane/links/7)

## Progression
- Consultez notre pré-publication qui sera publiée dans le cadre des travaux de l'EMNLP 2020 [ici] (https://arxiv.org/pdf/2010.02353.pdf).
- Consultez les benchmarks de traduction automatique que nous avons soumis [ici](https://github.com/masakhane-io/masakhane/blob/master/language_pairs.md) ! Vous ne voyez pas votre langue ? Veuillez soumettre une référence !
- Consultez notre [article] (https://arxiv.org/pdf/2003.11529) qui sera publié lors de l'atelier AfricaNLP de l'ICLR 2020.
- Consultez les articles écrits par nos participants [ici](https://github.com/masakhane-io/masakhane-community/blob/master/publications.md)
- En savoir plus sur nos [initiatives en cours](https://github.com/masakhane-io/masakhane-community/blob/master/initiatives.md)
- Consultez notre liste de [documents de la communauté](https://github.com/masakhane-io/masakhane-community/blob/master/community-documents.md)
- Lisez nos [notes de réunion hebdomadaire](https://github.com/masakhane-io/masakhane-community/tree/master/meetingsummaries)
- Suivez nos publications sur [Medium](https://medium.com/masakhane)

## Comment puis-je contribuer ?

Il existe de nombreuses façons de contribuer à **MASAKHANE**:
1. **ENTRAÎNER UN MODÈLE** - Contribuez à l'élaboration d'un modèle entraîné ainsi qu'au code correspondant pour votre langue.
2. **ANALYSE** - Contribuez à l'analyse des données/modèles pour toutes langues africaines. Vous n'avez pas besoin d'expérience technique pour cette tâche ! Si vous êtes linguiste, nous pouvons vous mettre en relation avec un spécialiste de la traduction automatique et vous pourrez contribuer à l'analyse.
3. **DONNÉES** - Aidez à construire ou à trouver des ensembles de données pour votre langue.
4. **DOCUMENTATION** - Aidez à documenter nos discussions, notre progression. Ceci est TRÈS précieux. Ou contribuez à la documentation du "notebook" de base qui améliorera l'expérience des autres.
5. **MENTORAT** - Fournir des conseils ou aider à ajuster les modèles en fonction des langues et des ensembles de données, ou aider les gens à démarrer.
6. **ADMIN** - Travailler avec autant de chercheurs peut être un véritable défi ! Aidez-nous à accomplir des tâches administratives.
7. **CALCUL** - Aidez à l'infrastructure et au calcul ! Avez-vous un ordinateur libre à donner ? Faites-le nous savoir ! Nous sommes toujours à la recherche de nouveaux ordinateurs !
8. **BRAINSTORM** - Participez à nos réunions hebdomadaires, donnez des conseils ou des idées.
9. **Raconter nos aventures** - Raconter notre histoire au monde entier en organisant des conférences sur la communauté, en contribuant à notre [publication Medium] (https://medium.com/masakhane) ou en collaborant avec les médias.
10. **MLOps & ML Engineering** - Vous aimez vous plonger dans l'aspect MLOps de l'Apprentissage Automatique ? Êtes-vous un développeur logiciel cherchant à perfectionner vos compétences d'ingénieur ML ? Rejoignez-nous afin de contribuer à la création d'outils permettant la reproductibilité, la collecte de données ainsi que le partage de modèles !

Vous souhaitez en savoir plus ? Consultez nos [initiatives en cours](https://github.com/masakhane-io/masakhane/blob/master/initiatives.md)

### Comment puis-je adhérer ?

1. Rejoignez notre [Slack](https://join.slack.com/t/masakhane-nlp/shared_invite/enQtODM3ODA3ODE0ODIwLTAyYzg3M2E3Nzg4Y2I3NzgxNDg4MmNlZDE4OTBjMzBjMjg4NTcxMWZlYTg3ZDljMTU4M2FjOTk3MDVjOWM2NGM)
2. Demandez à rejoindre notre [Groupe Google](https://groups.google.com/forum/#!forum/masakhane-mt)

3. Afin que nous puissions vous présenter sur notre page web [masakhane.io](https://masakhane.io), veuillez envoyer les informations suivantes à masakhanetranslation@gmail.com :
    - Votre nom complet
    - Un lien vers un réseau social préféré
    - La ou les langues sur lesquelles vous souhaitez travailler (ou votre spécialité principale - si vous êtes un expert en traduction automatique - et que vous souhaitez renforcer la communauté par ce biais).
    - Une photo
    - Votre affiliation et votre rôle.

*Veuillez être patient quant à la réception d'une réponse via notre adresse e-mail, nous sommes vraiment en décalage avec notre administration, en cette période de COVID-19.*

## Construire votre premier modèle de traduction automatique

Généralement, si vous avez une certaine expérience en programmation, nous vous encourageons à commencer votre voyage avec Masakhane en construisant une base de référence pour votre langue. 
**Vous vous sentez nerveux à l'idée de soumettre un projet ou vous vous demandez par où commencer ? Rejoignez nos réunions hebdomadaires et nous vous mettrons en relation avec un mentor**.

### 1. Jetez un œil à l'exemple de code suivant
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/masakhane-io/masakhane-mt/blob/master/starter_notebook_into_English_training.ipynb)  
Nous avons un [notebook colab d'exemple](https://github.com/masakhane-io/masakhane-mt/blob/master/starter_notebook_into_English_training.ipynb) qui entraîne un modèle de traduction de l'Anglais vers le Zoulou. Vous pouvez le sélectionner en allant dans la section `GitHub` lorsque vous ouvrez un nouveau projet.

### 2. Trouver des données pour ma langue ?!

C'est un énorme défi, mais heureusement, nous avons un endroit où démarrer! [Cet article](https://www.aclweb.org/anthology/P19-1310/) a été publié lors de l'ACL 2019. La version courte ? Il s'avère que la communauté des Témoins de Jéhovah ait traduit de nombreux documents et tous ne sont pas religieux. De plus, leur représentation linguistique est DIVERSE.

Veuillez consulter cette feuille de calcul [ICI](https://docs.google.com/spreadsheets/d/1p_HpKkrAlRDte04pgStsxaN8IJ4I0GgidVGIE_6VtMw/edit?usp=sharing) afin de voir si votre langue y figure, puis allez sur `Opus` pour trouver les liens vers les données : http://opus.nlpl.eu/JW300.php.

Nous fournissons également un script facilitant le téléchargement ainsi que le pré-traitement BPE des données JW300 depuis OPUS : `jw300_utils/get_jw300.py`. Il nécessite l'installation du paquet [Python opustools-pkg](https://pypi.org/project/opustools-pkg/).  
**Exemple:** Pour télécharger et pré-traiter les parties Acholi (ach) et Nyaneka (nyk) de JW300, lancez le script comme suit :  
`python get_jw300.py ach nyk --output_dir jw300`

#### Vous ne trouvez pas votre langue dans le jeu de données JW300 ?

Alors nous avons encore des solutions! Notre communauté a fait des recherches dans tous les sens! Rejoignez notre groupe Slack et Google afin de discuter de la marche à suivre! 

### 3. Exécutez le notebook!

Votre prochaine étape est d'utiliser le jeu de données JW300 dans le notebook colab et de le lancer. La plupart des conseils se trouvent dans le notebook lui-même. Nous l'améliorons constamment et sommes ouverts à toute recommandation. Vous avez du mal à vous lancer ? Alors travaillons ensemble afin de construire un notebook plus simple d'utilisation ! Créez un `Github issue` ou envoyez-nous un mail!

### 4. C'est fait! J'ai des résultats! Et maintenant ?

Excellent! Vous avez créé votre première base de référence. Maintenant nous devons mettre le code, les données ainsi que les résultats dans ce dépôt github.

Pour que nous puissions considérer votre soumission de résultats comme officielle, nous avons besoin de quelques éléments:

1. **Le notebook qui exécutera le code**. Le notebook DOIT fonctionner sur le compte de quelqu'un d'autre et les données qu'il utilise doivent être accessibles au public (c'est-à-dire que si je télécharge le notebook et l'exécute, il doit fonctionner - il ne doit donc pas utiliser de fichiers privés). Si vous vous demandez comment faire, rassurez-vous ! Envoyez-nous un message et nous collaborerons afin de nous assurer que la soumission est correcte ! :)

2. **Les jeux de test** - afin de répliquer et de tester vos résultats, nous avons besoin de jeux de test enregistrés et téléchargés séparément.

3. **Un fichier README.md** qui décrit (a) les données utilisées - particulièrement important s'il s'agit d'une combinaison de sources (b) toute modification notable du modèle (c) éventuellement une analyse de certaines phrases du modèle final.

4. **Le modèle lui-même.** Cela peut être sous la forme d'un lien *Google Drive* ou *Dropbox*. Nous allons bientôt trouver un endroit pour nos modèles entraînés.
Pour que les modèles soient entraînés davantage, utilisés pour l'apprentissage par transfert ou déployés, vous devez fournir :
    1. un checkpoint avec les paramètres (fichier `.ckpt`),
    2. le vocabulaire source et cible (`src_vocab.txt`, `trg_vocab.txt`),
    3. le fichier de configuration (`config.yaml`),
    4. et le cas échéant: les codes BPE ou les scripts de votre pipeline de prétraitement.
> Joey NMT enregistre les trois premiers dans le répertoire du modèle.

5. **Les résultats** - le BLEU score du train, du dev et de l'ensemble de test.

Nous allons continuer à développer nos techniques d'analyse, il est donc très important d'avoir une copie du modèle ainsi que des ensembles de test afin de ne pas avoir à relancer l'entrainement juste pour faire l'analyse.

Une fois que vous aurez tout ce qui précède, veuillez créer une `pull request` dans le dépôt. Voir les instructions [ici](https://help.github.com/en/articles/creating-a-pull-request-from-a-fork).

#### Structure de mon PR :

Voir aussi cet exemple pour la structure de votre contribution

Structure :
 ```
/benchmarks
  /<src-lang>-<tgt-lang>
    /<technique> -- this could be "jw300-baseline" or "fine-tuned-baseline" or "nig-newspaper-dataset"
      - notebook.ipynb
      - README.md
      - test.src
      - test.tgt
      - results.txt
      - src_vocab.txt
      - trg_vocab.txt
      - src.bpe
      - [trg.bpe if the bpe model is not joint with src]
      - config.yaml
      - any other files, if you have any
```

**Exemple:**
```
/benchmarks
  /en-xh
    /xhnavy-data-baseline
      - notebook.ipynb
      - README.md
      - test.xh
      - test.en
      - results.txt
      - src_vocab.txt
      - trg_vocab.txt
      - en-xh.4000.bpe
      - config.yaml
      - preprocessing.py
```
Voici un lien vers une pull request qui contient les éléments pertinents.

**Vous vous sentez nerveux à l'idée de contribuer à votre première pull request ou vous ne savez pas comment procéder? Ne vous découragez pas! Envoyez-nous un mail ou un message sur Slack et nous travaillerons ensemble afin que votre contribution soit au point!**.

### 5. J'ai une base de référence. Que dois-je faire pour l'améliorer ?

Cool! Il existe de nombreuses façons d'améliorer les résultats. Nous en avons souligné quelques-unes dans [ce document](MT4LRL.md). Vous avez d'autres idées? Envoyez-nous un message ou soumettez-nous un PR !

# Notes sur le déploiement des modèles

**Nous aimerions souligner qu'AUCUN des modèles formés n'est adapté à une utilisation en production**.  Dans notre article [ici](https://arxiv.org/pdf/2010.02353.pdf), nous explorons les effets sur les performances, de la formation d'un tel modèle sur les jeux de données JW300 (les modèles sont toujours incapables de généraliser à des domaines non religieux). **En règle générale, il ne faut jamais déployer un modèle NLP dans un domaine pour lequel il n'a pas été entraîné. Et même s'il est formé sur le domaine concerné, un modèle doit être analysé en détail afin de comprendre les biais ainsi que les inconvénients potentiels**. Ces modèles ont pour but de servir de **TRAVAUX EN COURS** afin de promouvoir la recherche et de mieux comprendre l'échec de tels systèmes.

# Code de conduite

Voir [Code de conduite](https://github.com/jaderabbit/masakhane/blob/master/CODE_OF_CONDUCT.md).

# Référence
Bibtex
```
@article{nekoto2020participatory,
  title={Participatory research for low-resourced machine translation: A case study in african languages},
  author={{$\forall$}, { } and Nekoto, Wilhelmina and Marivate, Vukosi and Matsila, Tshinondiwa and Fasubaa, Timi and Kolawole, Tajudeen and Fagbohungbe, Taiwo and Akinola, Solomon Oluwole and Muhammad, Shamsuddee Hassan and Kabongo, Salomon and Osei, Salomey and others},
  journal={Findings of EMNLP},
  year={2020}
}
```